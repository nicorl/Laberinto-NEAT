# Laberinto con IA (NEAT)

Este proyecto es una demostraci贸n del poder de la neuroevoluci贸n aplicada a la resoluci贸n de problemas. Un agente (representado por un c铆rculo) aprende a navegar y resolver un laberinto generado proceduralmente, utilizando el algoritmo **NEAT (NeuroEvolution of Augmenting Topologies)**.

El objetivo principal es mostrar c贸mo una red neuronal puede evolucionar de forma aut贸noma para encontrar la soluci贸n a un problema sin necesidad de programaci贸n expl铆cita de reglas.

## 锔 Tecnolog铆as

- **Python**: El lenguaje de programaci贸n principal.
- **Pygame**: Utilizado para la creaci贸n de la interfaz gr谩fica del laberinto y la visualizaci贸n del agente.
- **NEAT (neat-python)**: La biblioteca que implementa el algoritmo de neuroevoluci贸n, permitiendo el entrenamiento de las redes neuronales.

##  En qu茅 Consiste el Juego

El juego visualiza en tiempo real el proceso de entrenamiento de la IA.

- **El Laberinto**: Se genera de forma aleatoria en cada nueva generaci贸n de entrenamiento.
- **Los Agentes**: Una poblaci贸n de peque帽os c铆rculos que representan las redes neuronales en evoluci贸n. Cada agente intenta resolver el laberinto.
- **La Meta**: El cuadrado verde al final del laberinto. El objetivo de los agentes es llegar a ella.
- **El Fitness**: El "rendimiento" de cada agente se mide por su "fitness". Cuanto m谩s cerca llegue a la meta y m谩s tiempo permanezca activo, mayor ser谩 su fitness.
- **La Evoluci贸n**: Al final de cada generaci贸n, los agentes con el mayor fitness son seleccionados para "reproducirse" (mutar y cruzarse), pasando sus caracter铆sticas a la siguiente generaci贸n. Este ciclo se repite hasta que un agente logra resolver el laberinto.

##  Estructura del Proyecto

El c贸digo est谩 organizado en varios archivos para facilitar su comprensi贸n y mantenimiento:

-   `main.py`: El punto de entrada del programa. Inicializa Pygame, carga la configuraci贸n de NEAT y gestiona el bucle principal de entrenamiento y visualizaci贸n.
-   `laberinto.py`: Contiene la clase `Laberinto` responsable de generar el laberinto de forma procedural, dibujarlo en pantalla y gestionar la l贸gica de colisiones con las paredes.
-   `agente.py`: Define la clase `Agente`, que representa a cada individuo en la poblaci贸n de la IA. Gestiona el movimiento del agente, sus "sensores" para interactuar con el entorno y el c谩lculo de su fitness.
-   `config_neat.txt`: El archivo de configuraci贸n crucial para NEAT. Aqu铆 se definen todos los par谩metros del algoritmo gen茅tico, como el tama帽o de la poblaci贸n, las tasas de mutaci贸n y los criterios de aptitud.
-   `requirements.txt`: Lista de todas las dependencias de Python necesarias para ejecutar el proyecto.

##  C贸mo Instalar y Ejecutar

Para poner en marcha el proyecto, se recomienda usar un entorno virtual de Python.

1.  **Clonar el repositorio:**
    ```bash
    git clone [https://github.com/nicorl/Laberinto-NEAT.git](https://github.com/nicorl/Laberinto-NEAT.git)
    cd nombre-del-repo
    ```

2.  **Crear y activar el entorno virtual:**
    ```bash
    python3 -m venv venv
    source venv/bin/activate  # En Linux/macOS
    # O en Windows: venv\Scripts\activate
    ```

3.  **Instalar las dependencias:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ejecutar el programa:**
    ```bash
    python main.py
    ```

##  Explicaci贸n T茅cnica

El n煤cleo del proyecto reside en la interacci贸n entre los archivos `agente.py` y `neat-python`.

-   **Entradas de la Red Neuronal**: El agente percibe su entorno a trav茅s de **8 sensores**. Cada sensor mide la distancia a la pared m谩s cercana en una direcci贸n espec铆fica (0掳, 45掳, 90掳, etc.). Estos 8 valores son la entrada (`num_inputs = 8`) para la red neuronal del agente.
-   **Salidas de la Red Neuronal**: La red neuronal produce 4 valores (`num_outputs = 4`), uno para cada direcci贸n de movimiento: arriba, abajo, izquierda y derecha. El agente se mueve en la direcci贸n con el valor de salida m谩s alto.
-   **Funci贸n de Fitness**: El fitness de un genoma (la red neuronal del agente) se calcula como `1000 - distancia_a_meta`. Esto significa que cuanto m谩s cerca del objetivo est茅 el agente, mayor ser谩 su puntuaci贸n de aptitud. Si un agente logra alcanzar la meta, se le otorga un bonus de fitness para priorizar su genoma en la siguiente ronda de selecci贸n.

Este enfoque permite que la IA aprenda a evitar obst谩culos y a optimizar su camino hacia la meta de manera completamente aut贸noma, sin programaci贸n de reglas de navegaci贸n.
